---
title: "Bayesian Logistic Regression"
author: "Alex B.Dunbar"
date: "8/9/2021"
output:
  pdf_document:
      latex_engine: xelatex
  html_document: default
---
Clear environment, graphics and console
```{r}
# Clear environment ####
rm(list = ls()) 

# Clear plots
graphics.off()  # Clears plots, closes all graphics devices

# Clear console
cat("\014")  # ctrl+L
```
Install required packages
```{r include=FALSE}
# Install pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")

# Load contributed packages with pacman
pacman::p_load(pacman, rio, tidyverse, GGally, magrittr, broom, skimr)  #party, 
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# 1. Introduction
This is an implementation of Bayesian logistic regression using Metropolis-Hastings posterior sampling. The data is related to red variants of the Portuguese "Vinho Verde" wine.  There are 11 regressor variables (covariates) which are based on physiochemical tests.  The output variable is `good`, (1-good, 0-not-good) based on the `quality` variable which is a score between 0 and 10. `quality` is based on sensory data.


# 2. Import data.
The dataset is described in the publication by Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). [Modeling wine preferences by data mining from physicochemical properties.](https://www.sciencedirect.com/science/article/pii/S0167923609001377?casa_token=3l0RostJJXAAAAAA:QC5SBNWeoP2No8AVCA8EMu4R9yLCBh5gyZvsEMEVT1DxrzPwybfUyU0fWb8u4sqeqSyIUQBuIQI).
```{r}
wine <- read.csv("winequality-red.csv")
```
## Check for missing values
There are no `NA` values in the dataset.
```{r}
any(is.na(wine))
```
# 3. Classify "good" wines
We want to implement a logistic regression, therefore we want a response variable which assumes values either 0 or 1. Suppose we consider "good" a wine with quality above 6.5 (included).  We add a column called `good` that is `1` if the `quality` is greater than 6.5 and `0` if `quality` is less than 6.5. We also add a column of strings called `drinkable`, relating 1 and 0 to "good" and "bad" as appropriate.
```{r}
 wine %<>%
  mutate(good = ifelse(quality > 6, 1, 0)) %>%
  mutate(drinkable = ifelse(quality > 6, "good", "bad")) %>%
  mutate(quality = factor(quality, levels=1:10))
```
Remove spaces from names to make references easier.
```{r}
colnames(wine) <- c("fixed_acidity", "volatile_acidity", "citric_acid",
                      "residual_sugar", "chlorides", "free_sulfur_dioxide",
                      "total_sulfur_dioxide", "density", "pH", "sulphates",
                      "alcohol", "quality", "good", "drinkable")
```
The structure of the dataset, `str(wine)`, will confirm that there are no `NA` values, the feature names, the feature type (num, Factor, chr) and the first 10 values.
```{r}
str(wine)
```
Overview of dataset
```{r}
wine %>% skim()
```
Number of good and bad wines from each quality category
```{r}
xtabs(~ good + quality, data=wine)
```

# 4. Frequentist Logistic Regression

We first implement a classic logistic regression model. From this model we can obtain the model coefficients.  These coefficients are the MLE estimates which can be used as the initialisation values when we run the Metropolis-Hastings sampling. The classic logistic model is computed using the generalised linear model (glm) with `good` being a function of all other covariates except `quality` and `drinkable`.

```{r}
fit <- glm(
  good ~ . - quality - drinkable,
  data = wine,
  family = binomial(link="logit")
)
```
## Significant coefficients
The significant coefficients are labelled in the last column of the summary() function.  Most significant coefficients are:

* `sulphates`(Pr($\alpha$ > 6.924 = 4.39e-12)),
the `sulphates` coefficient is 3.750. A positive predictor whereby larger values of sulphate will predict a "good" wine.
* `alcohol`(Pr($\alpha$ > 5.724 = 1.04e-08)),
the `alcohol` coefficient is 0.7533. A positive predictor whereby larger values of alcohol will predict a "good" wine.
* `volatile_acidity` (Pr($\alpha$ > |-3.291| = 9.99e-4)), and
the `volatile_acidity` coefficient is -2.581. A negative predictor whereby larger values of volatile acidity will predict a "not-good" wine.
* `total_sulfur_dioxide` (Pr($\alpha$ > |-3.378| = 7.31e-4))
the `total_sulfur_dioxide` coefficient is -0.026. A negative predictor whereby larger values of total sulfur dioxide will predict a "not-good" wine.

```{r}
fit %>% summary()
```


# 5. Impact on outcome by varying total_sulfur_dioxide
By fixing all coefficients and varying one, we can see the impact of one particular coefficient has on the probabilistic outcome of the logistic regression. 

As a comparison I have fixed all significant coefficients in turn (`total_sulfur_dioxide`, `volatile_acidity`, `sulphates` and `alcohol`)

First, we save coefficients to their own variable.
```{r}
b0 <- fit$coefficients[1]  # Intercept = 242.76251933
b1 <- fit$coefficients[2]  # fixed_acidity = 0.27495289
b2 <- fit$coefficients[3]  # volatile_acidity = -2.58100211
b3 <- fit$coefficients[4]  # citric_acid = 0.56779433
b4 <- fit$coefficients[5]  # residual_sugar = 0.23946420
b5 <- fit$coefficients[6]  # chlorides = -8.81636544
b6 <- fit$coefficients[7]  # free_sulfur_dioxide = 0.01082060
b7 <- fit$coefficients[8]  # total_sulfur_dioxide = -0.01653061
b8 <- fit$coefficients[9]  # density = -257.79757874
b9 <- fit$coefficients[10]  # pH = 0.22418522
b10 <- fit$coefficients[11]  # sulphates = 3.74987886
b11 <- fit$coefficients[12]  # alcohol = 0.75333905
```
Then save each individual mean values
```{r}
fixed_acidity_mean <- mean(wine$fixed_acidity)
volatile_acidity_mean <- mean(wine$volatile_acidity)
citric_acid_mean <- mean(wine$citric_acid)
residual_sugar_mean <- mean(wine$residual_sugar)
chlorides_mean <- mean(wine$chlorides)
free_sulfur_dioxide_mean <- mean(wine$free_sulfur_dioxide)
total_sulfur_dioxide_mean <- mean(wine$total_sulfur_dioxide)
density_mean <- mean(wine$density)
pH_mean <- mean(wine$pH)
sulphates_mean <- mean(wine$sulphates)
alcohol_mean <- mean(wine$alcohol)
```
Compute the range of each significant coefficient, `total_sulfur_dioxide`, `sulphates`, `alcohol`, and `volatile_acidity`
```{r}
total_sulfur_dioxide_range <- seq(from=min(wine$total_sulfur_dioxide), to=max(wine$total_sulfur_dioxide), by=1)
sulphates_range <- seq(from=min(wine$sulphates), to=max(wine$sulphates), by=0.002)
alcohol_range <- seq(from=min(wine$alcohol), to=max(wine$alcohol), by=0.05)
volatile_acidity_range <- seq(from=min(wine$volatile_acidity), to=max(wine$volatile_acidity), by=0.002)
```
Plot of the range histogram of each of the four most significant covariates.
```{r, echo=FALSE}
par(mfrow=c(2,2))
hist(total_sulfur_dioxide_range, xlab="Range", main="Total Sulfur Dioxide")
hist(sulphates_range, xlab="Range", main="Sulphates")
hist(alcohol_range, xlab="Range", main="Alcohol")
hist(volatile_acidity_range, xlab="Range", main="Volatile Acidity")
```

Calculate probabilities for each significant coefficient
```{r}
total_sulfur_dioxide_GOOD <- b0 + b1*fixed_acidity_mean + b2*volatile_acidity_mean +
  b3*citric_acid_mean + b4*residual_sugar_mean + b5*chlorides_mean + b6*free_sulfur_dioxide_mean +
  b7*total_sulfur_dioxide_range + b8*density_mean + b9*pH_mean + b10*sulphates_mean + b11*alcohol_mean

sulphates_GOOD <- b0 + b1*fixed_acidity_mean + b2*volatile_acidity_mean +
  b3*citric_acid_mean + b4*residual_sugar_mean + b5*chlorides_mean + b6*free_sulfur_dioxide_mean +
  b7*total_sulfur_dioxide_mean + b8*density_mean + b9*pH_mean + b10*sulphates_range + b11*alcohol_mean

alcohol_GOOD <- b0 + b1*fixed_acidity_mean + b2*volatile_acidity_mean +
  b3*citric_acid_mean + b4*residual_sugar_mean + b5*chlorides_mean + b6*free_sulfur_dioxide_mean +
  b7*total_sulfur_dioxide_mean + b8*density_mean + b9*pH_mean + b10*sulphates_mean + b11*alcohol_range

volatile_acidity_GOOD <- b0 + b1*fixed_acidity_mean + b2*volatile_acidity_range +
  b3*citric_acid_mean + b4*residual_sugar_mean + b5*chlorides_mean + b6*free_sulfur_dioxide_mean +
  b7*total_sulfur_dioxide_mean + b8*density_mean + b9*pH_mean + b10*sulphates_mean + b11*alcohol_mean
```

Calculate log odds probabilities for each
```{r}
total_sulfur_dioxide_probs <- exp(total_sulfur_dioxide_GOOD)/(1 + exp(total_sulfur_dioxide_GOOD))
sulphates_probs <- exp(sulphates_GOOD) / (1 + exp(sulphates_GOOD))
alcohol_probs <- exp(alcohol_GOOD) / (1 + exp(alcohol_GOOD))
volatile_acidity_probs <- exp(volatile_acidity_GOOD) / (1 + exp(volatile_acidity_GOOD))
```

## Plot the results.

The plots of each of the four covariates are the probabilities across the range of 
```{r, echo=FALSE}
par(mfrow=c(2,2))
plot(total_sulfur_dioxide_range, total_sulfur_dioxide_probs, 
     ylim=c(0,1), type="l", lwd=3, lty=2, col="gold", 
     xlab="Total Sulfur Dioxide", ylab="P(conversion)", main="Probability of conversion")

plot(sulphates_range, sulphates_probs, 
     ylim=c(0,1), type="l", lwd=3, lty=2, col="gold", 
     xlab="Total Sulphates", ylab="P(conversion)", main="Probability of conversion")

plot(alcohol_range, alcohol_probs, 
     ylim=c(0,1), type="l", lwd=3, lty=2, col="gold", 
     xlab="Total Alcohol", ylab="P(conversion)", main="Probability of conversion")

plot(volatile_acidity_range, volatile_acidity_probs, 
     ylim=c(0,1), type="l", lwd=3, lty=2, col="gold", 
     xlab="Total Volatile Acidity", ylab="P(conversion)", main="Probability of conversion")
```

# 6. Bayesian Logistic Regression

The following is a Bayesian logistic regression analysis. To perform a Bayesian analysis via Metropolis-Hastings algorithm we write a function defining the target distribution of the Beta coefficients.  We work in terms of log posterior to avoid numerical problems with computer computation.

## Likelihood.
The likelihood is a product of Bernoulli likelihoods for each combination of covariate and response variable for the i-th term.
$$ L(\beta; y, x) = \prod_{i=1}^n \bigg(\frac{\text{exp}(x_i \beta)}{1 + \text{exp}(x_i \beta)}\bigg)^{y_i}\bigg(1- \frac{\text{exp}(x_i \beta)}{1 + \text{exp}(x_i \beta)}\bigg)^{1-y_i} $$
## Log-likelihood
$$ \log L (\beta; y, x) = \sum_{i=1}^n y_i(x_i \beta) - \log [1 + \text{exp}(x_i \beta)] $$

## Prior
Independent normal prior distributions for each $\beta_j, j=0,1,\dots,k$, such that $\beta_j \sim N(0, 100)$

## Log posterior distribution
This function will compute the log-likelihood and the log-prior and return the log-posterior.  The function is called in the Metropolis-Hastings algorithm to compute the distribution for the proposed value ($\beta^*$) for the next value the chain to compare against the existing value in the chain.
```{r}
lpost.LR <- function(beta, x, y) {
  # beta: vector of coefficients
  # x: covariates (regressors)
  # y: response variable
  # -------------------------------
  # eta is the matrix product of the covariates and the coefficients
  eta <- as.numeric(x %*% beta)
  # logp: y=1, in terms of logistic function
  logp <- eta - log(1 + exp(eta))  # in log scale
  # logq: y=0, expressed in terms of logistic function
  logq <- log(1 - exp(logp))
  # sum of both contributions: when y=1 + when y=0
  logl <- sum(logp[y==1]) + sum(logq[y==0])
  # log prior: normal indep prior dists $N(0, 100)$
  lprior <- sum(dnorm(beta, 0, 100,log = T))  # 10: mixed, 50 var, 100 large var, 20 like 10, 5 low
  # return log posterior (likelihood + prior)
  return(logl + lprior)
}
```
Set seed for reproducible results
```{r}
set.seed(1234)
```
## Number of simulations
```{r}
S <- 20000
```
Set `X` and `y` variables
```{r}
X = cbind(rep(1, nrow(wine)), wine$fixed_acidity, wine$volatile_acidity, wine$citric_acid,
          wine$residual_sugar, wine$chlorides, wine$free_sulfur_dioxide, wine$total_sulfur_dioxide,
          wine$density, wine$pH, wine$sulphates, wine$alcohol)

y <- wine$good[1]
```
## Initialisations for the coefficients

The first initialisation contains the MLE estimates for each coefficient. The remaining three initialisations are randomly selected values between 100 and 200 from the uniform distribution $runif(48, 100, 200)$.
```{r}
# init <- matrix(data=c(runif(20, min = 100, max = 200)), nrow=4, ncol=5, byrow = T)  # for testing
init <- matrix(data=c(runif(48, min = 100, max = 200)), nrow=4, ncol=12, byrow = T)
```
## Run a Metropolis-Hastings algorithm
```{r}
# First initialisation
beta_mat_init1 <- matrix(NA, nrow = S, ncol = ncol(X))
k <- ncol(beta_mat_init1)
beta_mat_init1[1,] <- init[1,]
#beta_mat_init1[1,] <- as.numeric(coefficients(fit))  # initialise with MLE of each coefficient
acc <- 0
for (iter in 2:S) {
  # simulate all (k) values using previous value of beta as mean and set sd
  beta_star <- rnorm(k, beta_mat_init1[iter-1,], 5)
  # compute target distribution for proposed value
  newpost = lpost.LR(beta_star, X, y)
  # compute target distribution for old value
  oldpost = lpost.LR(beta_mat_init1[iter-1,], X, y)  # symmetric dist => no ratio computed
  
  # acceptance step, in log scale
  if (runif(1,0,1) > exp(newpost - oldpost)) {
    # chain doesn't move
    beta_mat_init1[iter,] = beta_mat_init1[iter-1,]
  } else {
    # add to chain and add 1 to counter
    beta_mat_init1[iter,] = beta_star
    acc=acc + 1
  }
  #if (iter%%1000 == 0) {print(c(iter, acc/iter))}
}
print(c(iter, acc/iter))

# Second initialisation
beta_mat_init2 <- matrix(NA, nrow = S, ncol = ncol(X))
k <- ncol(beta_mat_init2)
beta_mat_init2[1,] <- init[2,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k, beta_mat_init2[iter-1,], 5)
  newpost = lpost.LR(beta_star, X, y)
  oldpost = lpost.LR(beta_mat_init2[iter-1,], X, y)
  if (runif(1,0,1) > exp(newpost - oldpost)) {
    beta_mat_init2[iter,] = beta_mat_init2[iter-1,]
  } else {
    beta_mat_init2[iter,] = beta_star
    acc=acc + 1
  }
  #if (iter%%1000==0) {print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))

# Third initialisation
beta_mat_init3 <- matrix(NA,nrow=S,ncol=ncol(X))
k <- ncol(beta_mat_init3)
beta_mat_init3[1,] <- init[3,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k,beta_mat_init3[iter-1,], 5)
  newpost=lpost.LR(beta_star,X,y)
  oldpost=lpost.LR(beta_mat_init3[iter-1,],X,y)
  if(runif(1,0,1)>exp(newpost-oldpost)){
    beta_mat_init3[iter,]=beta_mat_init3[iter-1,]
  } else{
    beta_mat_init3[iter,]=beta_star
    acc=acc+1
  }
  #if(iter%%1000==0){print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))

# Forth initialisation
beta_mat_init4 <- matrix(NA,nrow=S,ncol=ncol(X))
k <- ncol(beta_mat_init4)
beta_mat_init4[1,] <- init[4,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k,beta_mat_init4[iter-1,], 5)
  newpost=lpost.LR(beta_star,X,y)
  oldpost=lpost.LR(beta_mat_init4[iter-1,],X,y)
  if(runif(1,0,1)>exp(newpost-oldpost)){
    beta_mat_init4[iter,]=beta_mat_init4[iter-1,]
  } else{
    beta_mat_init4[iter,]=beta_star
    acc=acc+1
  }
  #if(iter%%1000==0){print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))
```
Plot the chains for each coefficient (same plot)

```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat_init1[,1], type="l", col="magenta", main=expression(beta[0]))
lines(beta_mat_init2[,1], type="l", col="green")
lines(beta_mat_init3[,1], type="l", col="red")
lines(beta_mat_init4[,1], type="l", col="blue")
abline(h=fit$coefficients[1],col="red",lty=2)

plot(beta_mat_init1[,2], type="l", col="magenta", main=expression(beta[1]))  #, ylim=(c(-30, 50))
lines(beta_mat_init2[,2], type="l", col="green")
lines(beta_mat_init3[,2], type="l", col="red")
lines(beta_mat_init4[,2], type="l", col="blue")
abline(h=fit$coefficients[2],col="red",lty=2)

plot(beta_mat_init1[,3], type="l", col="magenta", main=expression(beta[2]))
lines(beta_mat_init2[,3], type="l", col="green")
lines(beta_mat_init3[,3], type="l", col="red")
lines(beta_mat_init4[,3], type="l", col="blue")
abline(h=fit$coefficients[3],col="red",lty=2)

plot(beta_mat_init1[,4], type="l", col="magenta", main=expression(beta[3]))
lines(beta_mat_init2[,4], type="l", col="green")
lines(beta_mat_init3[,4], type="l", col="red")
lines(beta_mat_init4[,4], type="l", col="blue")
abline(h=fit$coefficients[4],col="red",lty=2)

plot(beta_mat_init1[,5], type="l", col="magenta", main=expression(beta[4]))
lines(beta_mat_init2[,5], type="l", col="green")
lines(beta_mat_init3[,5], type="l", col="red")
lines(beta_mat_init4[,5], type="l", col="blue")
abline(h=fit$coefficients[5],col="red",lty=2)

plot(beta_mat_init1[,6], type="l", col="magenta", main=expression(beta[5]))
lines(beta_mat_init2[,6], type="l", col="green")
lines(beta_mat_init3[,6], type="l", col="red")
lines(beta_mat_init4[,6], type="l", col="blue")
abline(h=fit$coefficients[6],col="red",lty=2)
```

```{r}
fit$coefficients[1:6]
```


```{r, echo=FALSE}
par(mfrow=c(3,2))

plot(beta_mat_init1[,7], type="l", col="magenta", main=expression(beta[6]))  # , ylim=(c(-30, 30))
lines(beta_mat_init2[,7], type="l", col="green")
lines(beta_mat_init3[,7], type="l", col="red")
lines(beta_mat_init4[,7], type="l", col="blue")
abline(h=fit$coefficients[7],col="red",lty=2)

plot(beta_mat_init1[,8], type="l", col="magenta", main=expression(beta[7]))  # , ylim=(c(-30, 40))
lines(beta_mat_init2[,8], type="l", col="green")
lines(beta_mat_init3[,8], type="l", col="red")
lines(beta_mat_init4[,8], type="l", col="blue")
abline(h=fit$coefficients[8],col="red",lty=2)

plot(beta_mat_init1[,9], type="l", col="magenta", main=expression(beta[8]))
lines(beta_mat_init2[,9], type="l", col="green")
lines(beta_mat_init3[,9], type="l", col="red")
lines(beta_mat_init4[,9], type="l", col="blue")
abline(h=fit$coefficients[9],col="red",lty=2)

plot(beta_mat_init1[,10], type="l", col="magenta", main=expression(beta[9]))
lines(beta_mat_init2[,10], type="l", col="green")
lines(beta_mat_init3[,10], type="l", col="red")
lines(beta_mat_init4[,10], type="l", col="blue")
abline(h=fit$coefficients[10],col="red",lty=2)

plot(beta_mat_init1[,11], type="l", col="magenta", main=expression(beta[10]))
lines(beta_mat_init2[,11], type="l", col="green")
lines(beta_mat_init3[,11], type="l", col="red")
lines(beta_mat_init4[,11], type="l", col="blue")
abline(h=fit$coefficients[11],col="red",lty=2)

plot(beta_mat_init1[,12], type="l", col="magenta", main=expression(beta[11]))  # , ylim=(c(-30, 50))
lines(beta_mat_init2[,12], type="l", col="green")
lines(beta_mat_init3[,12], type="l", col="red")
lines(beta_mat_init4[,12], type="l", col="blue")
abline(h=fit$coefficients[12],col="red",lty=2)
```
## Comment
```{r}
fit$coefficients[7:12]
```
$\beta_0$ (`Intercept`: 242.7625): No convergence with MLE.  All four chains do converge to a value around zero.
$\beta_1$ (`fixed_acidity`: 0.275): First chain containing MLE converges to a value close but slightly under the coefficient.  The other three chains containing random initialisations converge to a value approximately 20-30.
$\beta_2$ (`volative_acidity`: -2.581): All four chains converge to a value close to the coefficient.
$\beta_3$ (`citric_acid`: 0.568): All four chains converge to a value close to the coefficient.
$\beta_4$ (`residual_sugar`: 0.239): All four chains converge to a value close to the coefficient.
$\beta_5$ (`chlorides`: -8.816): All four chains converge to a value close to the coefficient.
$\beta_6$ (`free_sulfur_dioxide`: 0.011): First chain containing MLE converges to a value close but slightly under the coefficient.  The other three chains containing random initialisations converge to a value approximately 20-30.
$\beta_7$ (`total_sulfur_dioxide`: -0.017): First chain converges to a value just below coefficient but chains 2-4 don't converge to coefficient.
$\beta_8$ (`density`: -257.798): First chain converges to a value at about the coefficient but chains 2-4 converge to a value slightly above the coefficient
$\beta_9$ (`pH`: 0.224): All four chains converge to a value close to the coefficient.
$\beta_{10}$ (`sulphates`: 3.750): All four chains converge to a value close to the coefficient.
$\beta_{11}$ (`alcohol`: 0.753): First chain converges to a value at about the coefficient but chains 2-4 converge to a value above the coefficient



--------------------------------------------------------------------------------


## Comment

How good is the distribution for the parameter?

* varied standard deviation of the prior in the posterior distribution function (0.5, 1, 5, 10, 20, 50)
> increasing the standard deviation increases the instability
> decreasing the standard deviation decreases ability to find convergence with "true" value
* varied standard deviation of the Metropolis-Hastings algorithm (0.5, 1, 5, 10, 20, 50)
* varied the random initialised values (+/- 100, 0-1, 0-10, 0-100, 10-100, 100-200, 500-1000)
> some ranges close to zero produce errors


# 7. Posterior Predictive Distribution
Approximate the posterior predictive distribution of an unobserved variable characterised by the following values for each covariate:
```{r}
fixed_acidity <- 7.5
volatile_acidity <- 0.6
citric_acid <- 0.0
residual_sugar <- 1.7
chlorides <- 0.085
free_sulfur_dioxide <- 5
total_sulfur_dioxide <- 45
density <- 0.9965
pH <- 3.4
sulphates <- 0.63
alcohol <- 12
```


```{r}
S <- 20000
beta_mat2 <- matrix(NA, nrow = S, ncol = ncol(X))
beta_mat2[1,] <- as.numeric(coefficients(fit))

y_new <- c(1)
x_new <- c(1, fixed_acidity, volatile_acidity, citric_acid, residual_sugar,
           chlorides, free_sulfur_dioxide, total_sulfur_dioxide, density,
           pH, sulphates, alcohol)
```

new model
```{r}
library(mvtnorm)

# prediction

Omega_prop <- solve(t(X) %*% X)
k <- ncol(beta_mat2)
acc <- 0
for(iter in 2:S)
{
  # 1. Propose a new set of values
  beta_star <- rmvnorm(1, beta_mat2[iter-1,], 1.5 * Omega_prop)
  
  # 2. Compute the posterior density on the proposed value and on the old value  
  newpost=lpost.LR(t(beta_star), X, y)
  oldpost=lpost.LR(matrix(beta_mat2[iter-1,], ncol=1), X, y)
  
  # 3. Acceptance step
  if (runif(1, 0, 1) > exp(newpost - oldpost)) {
    beta_mat2[iter,] = beta_mat2[iter-1,]
  } else {
    beta_mat2[iter,] = beta_star
    acc = acc + 1
  }
  # 4. Print the stage of the chain
  if (iter%%1000 == 0){ print(c(iter, acc/iter)) }
  
  # 5. Prediction 
  p_new <- exp(sum(beta_mat2[iter,] * x_new) ) / (1 + exp(sum(beta_mat2[iter,] * x_new) ))
  y_new[iter] <- rbinom(1,1,prob=p_new)
}
```

Plots

```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat2[,1],type="l", ylab=expression(beta[0]))
abline(h=fit$coefficients[1],col="red",lty=2)
plot(beta_mat2[,2],type="l", ylab=expression(beta[1]))
abline(h=fit$coefficients[2],col="red",lty=2)
plot(beta_mat2[,3],type="l", ylab=expression(beta[2]))
abline(h=fit$coefficients[3],col="red",lty=2)
plot(beta_mat2[,4],type="l", ylab=expression(beta[3]))
abline(h=fit$coefficients[4],col="red",lty=2)
plot(beta_mat2[,5],type="l", ylab=expression(beta[4]))
abline(h=fit$coefficients[5],col="red",lty=2)
plot(beta_mat2[,6],type="l", ylab=expression(beta[5]))
abline(h=fit$coefficients[6],col="red",lty=2)
```

Plots


```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat2[,7],type="l", ylab=expression(beta[6]))
abline(h=fit$coefficients[7],col="red",lty=2)
plot(beta_mat2[,8],type="l", ylab=expression(beta[7]))
abline(h=fit$coefficients[8],col="red",lty=2)
plot(beta_mat2[,9],type="l", ylab=expression(beta[8]))
abline(h=fit$coefficients[9],col="red",lty=2)
plot(beta_mat2[,10],type="l", ylab=expression(beta[9]))
abline(h=fit$coefficients[10],col="red",lty=2)
plot(beta_mat2[,11],type="l", ylab=expression(beta[10]))
abline(h=fit$coefficients[11],col="red",lty=2)
plot(beta_mat2[,12],type="l", ylab=expression(beta[11]))
abline(h=fit$coefficients[12],col="red",lty=2)
```
$\beta_0$ (`Intercept`: 242.7625): ## No convergence with MLE.  converge to a value around zero.
$\beta_1$ (`fixed_acidity`: 0.275): ##  
$\beta_2$ (`volative_acidity`: -2.581): ## 
$\beta_3$ (`citric_acid`: 0.568): ## 
$\beta_4$ (`residual_sugar`: 0.239): ## 
$\beta_5$ (`chlorides`: -8.816): ## 
$\beta_6$ (`free_sulfur_dioxide`: 0.011): ## 
$\beta_7$ (`total_sulfur_dioxide`: -0.017): ## 
$\beta_8$ (`density`: -257.798): ## 
$\beta_9$ (`pH`: 0.224): ## 
$\beta_{10}$ (`sulphates`: 3.750): ## 
$\beta_{11}$ (`alcohol`: 0.753): ## 

--------------------------------------------------------------------------------

```{r}
table(y_new[15000:20000])
```
# 8. metrop() analysis of Q6
Implementation of the `metrop()` function was through the [MCMC Package Example, Charles J. Geyer](https://cran.r-project.org/web/packages/mcmc/vignettes/demo.pdf)


```{r}
library(mcmc)
out <- glm(good ~ . - quality - drinkable, data=wine, family=binomial, x=TRUE)
```

```{r}
lupost_factory <- function(x, y) function(beta) {
  eta <- as.numeric(x %*% beta)
  logp <- ifelse(eta < 0, eta - log1p(exp(eta)), - log1p(exp(- eta)))
  logq <- ifelse(eta < 0, - log1p(exp(eta)), - eta - log1p(exp(- eta)))
  logl <- sum(logp[y == 1]) + sum(logq[y == 0])
  return(logl - sum(beta^2) / 8)
}
lupost <- lupost_factory(out$x, out$y)
```


```{r}
set.seed(1234)
beta.init <- as.numeric(coefficients(out))
out <- metrop(lupost, beta.init, 1e3)

names(out)
```
Look at the acceptance rate.

```{r}
out$accept
```
This is very low, so we can adjust the scale parameter to find an acceptance rate around 20%.
```{r}
#out <- metrop(out, scale = 0.005)  # 0.0075
out <- metrop(out, scale = c(0.005, 0.00005, 0.00005, 0.00005, 0.00005, 0.00005, 0.00005, 0.00005, 0.0005, 0.00005, 0.00005, 0.00005))
out$accept
```


```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(ts(out$batch)[,1], ylab=expression(beta[0]))
abline(h=fit$coefficients[1],col="red",lty=2)
plot(ts(out$batch)[,2], ylab=expression(beta[1]))
abline(h=fit$coefficients[2],col="red",lty=2)
plot(ts(out$batch)[,3], ylab=expression(beta[2]))
abline(h=fit$coefficients[3],col="red",lty=2)
plot(ts(out$batch)[,4], ylab=expression(beta[3]))
abline(h=fit$coefficients[4],col="red",lty=2)
plot(ts(out$batch)[,5], ylab=expression(beta[4]))
abline(h=fit$coefficients[5],col="red",lty=2)
plot(ts(out$batch)[,6], ylab=expression(beta[5]))
abline(h=fit$coefficients[6],col="red",lty=2)
```


```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(ts(out$batch)[,7], ylab=expression(beta[7]))
abline(h=fit$coefficients[7],col="red",lty=2)
plot(ts(out$batch)[,8], ylab=expression(beta[8]))
abline(h=fit$coefficients[8],col="red",lty=2)
plot(ts(out$batch)[,9], ylab=expression(beta[9]))
abline(h=fit$coefficients[9],col="red",lty=2)
plot(ts(out$batch)[,10], ylab=expression(beta[10]))
abline(h=fit$coefficients[10],col="red",lty=2)
plot(ts(out$batch)[,11], ylab=expression(beta[11]))
abline(h=fit$coefficients[11],col="red",lty=2)
plot(ts(out$batch)[,12], ylab=expression(beta[12]))
abline(h=fit$coefficients[12],col="red",lty=2)
```
## VISUAL COMPARISON

$\beta_0$ (`Intercept`: 242.7625): ## 
$\beta_1$ (`fixed_acidity`: 0.275): ## 
$\beta_2$ (`volatile_acidity`: -2.581): ## 
$\beta_3$ (`citric_acid`: 0.568): ## 
$\beta_4$ (`residual_sugar`: 0.239): ## 
$\beta_5$ (`chlorides`: -8.816): ## 
$\beta_6$ (`free_sulfur_dioxide`: 0.011): 
$\beta_7$ (`total_sulfur_dioxide`: -0.017): ## 
$\beta_8$ (`density`: -257.798): ## 
$\beta_9$ (`pH`: 0.224): ## 
$\beta_{10}$ (`sulphates`: 3.750): ## 
$\beta_{11}$ (`alcohol`: 0.753): ## 


```{r}
summ <- matrix(NA, nrow=12, ncol=6)
for (i in 1:12) {
  summ[i,1] = mean(beta_mat_init1[2000:10000,i])
  summ[i,2] = sd(beta_mat_init1[2000:10000,i])
  summ[i,3] = mean(beta_mat2[12000:20000,i])
  summ[i,4] = sd(beta_mat2[12000:20000,i])
  summ[i,5] = mean(ts(out$batch)[,i])
  summ[i,6] = sd(ts(out$batch)[,i])
}
colnames(summ) <- c("Mean_MH", "SD_MH", "Mean_MH2", "SD_MH2", "Mean_Metrop", "SD_Metrop")
rownames(summ) <- c("Intercept", "fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar",
                    "chlorides", "free_sulfur_dioxide", "total_sulfur_dioxide", "density",
                    "pH", "sulphates", "alcohol")
```
```{r}
knitr::kable(summ)
```
Histogram of spread of chain values
```{r}
# hist(beta_mat_init1[,1])
# ci0 <- quantile(beta_mat_init1[,1], prob=c(.025,.975)) 
coeffs <- c("Intercept", "Fixed Acidity", "Volatile Acidity", "Citric Acid", "Residual Sugar",
                    "Chlorides", "Free Sulfur Dioxide", "Total Sulfur Dioxide", "Density",
                    "pH", "Sulphates", "Alcohol")

```
```{r}
par(mfrow=c(3,2)) 
for (i in 1:6) {
hist(beta_mat_init1[,i], main=coeffs[i], prob=TRUE); abline(v=c(summ[i,1],quantile(beta_mat_init1[,i], prob=c(.025,.975))), col="red")
}
```
```{r}
par(mfrow=c(3,2)) 
for (i in 7:12) {
hist(beta_mat_init1[10000:20000,i], main=coeffs[i], prob=TRUE); abline(v=c(summ[i,1],quantile(beta_mat_init1[10000:20000,i], prob=c(.025,.975))), col="red")
}
```


# EXTRA
The following is not part of the scope of the analysis.  It contains normalised data as a comparison to the un-normalised. The outcome is that each coefficient chain is closer to convergence to the MLE value.  The second model using `Omega_prop` <- solve(t(X) %*% X) is a much more stable chain compared to the same using un-normalised data.

## Normalise Data
Normalised data to compare results

```{r}
response <- wine$good
wine = wine[, -c(12, 13, 14)]

normalise <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

wine_norm <- as.data.frame(lapply(wine, normalise))
y = response
x = wine_norm
# Combine data

dat <- cbind(x, y)
names(dat)[12] <- "GOOD"
# test <- dat[1:20,]  # match with testPred
# train <- dat[c(21:100),]
y = dat$GOOD
# x = train[,c(1:11)]
X = cbind(rep(1, nrow(dat)), dat$fixed_acidity, dat$volatile_acidity, dat$citric_acid,
          dat$residual_sugar, dat$chlorides, dat$free_sulfur_dioxide, dat$total_sulfur_dioxide,
          dat$density, dat$pH, dat$sulphates, dat$alcohol)
```
Fit using normalised covariates
```{r}
library(Metrics)
# 
# fit <- glm(GOOD ~ ., data = dat)  #; fit$coefficients
# pred <- predict(fit, test[, c(-12)])
# rmse(actual = test$GOOD, predicted=pred)
# summary(fit)

fit <- glm(GOOD ~ ., data = dat, family = binomial(link="logit"))  #; fit$coefficients
pred <- predict(fit, dat[, c(-12)])
rmse(actual = dat$GOOD, predicted=pred)

```
```{r}
lpost.LR <- function(beta, x, y) {
  eta <- as.numeric(x %*% beta)
  logp <- eta - log(1 + exp(eta))
  logq <- log(1 - exp(logp))
  logl <- sum(logp[y==1]) + sum(logq[y==0])
  lprior <- sum(dnorm(beta, 0, 100,log = T))
  return(logl + lprior)
}
```


```{r}
S <- 10000
init <- matrix(data=c(runif(48, min = 0, max = 0)), nrow=4, ncol=12, byrow = T)

# First initialisation
beta_mat_init1 <- matrix(NA, nrow = S, ncol = ncol(X))
k <- ncol(beta_mat_init1)
beta_mat_init1[1,] <- init[1,]
#beta_mat_init1[1,] <- as.numeric(coefficients(fit))  # initialise with MLE of each coefficient
acc <- 0
for (iter in 2:S) {
  # simulate all (k) values using previous value of beta as mean and set sd
  beta_star <- rnorm(k, beta_mat_init1[iter-1,], 0.1)
  # compute target distribution for proposed value
  newpost = lpost.LR(beta_star, X, y)
  # compute target distribution for old value
  oldpost = lpost.LR(beta_mat_init1[iter-1,], X, y)  # symmetric dist => no ratio computed
  
  # acceptance step, in log scale
  if (runif(1,0,1) > exp(newpost - oldpost)) {
    # chain doesn't move
    beta_mat_init1[iter,] = beta_mat_init1[iter-1,]
  } else {
    # add to chain and add 1 to counter
    beta_mat_init1[iter,] = beta_star
    acc=acc + 1
  }
  #if (iter%%1000 == 0) {print(c(iter, acc/iter))}
}
print(c(iter, acc/iter))

# Second initialisation
beta_mat_init2 <- matrix(NA, nrow = S, ncol = ncol(X))
k <- ncol(beta_mat_init2)
beta_mat_init2[1,] <- init[2,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k, beta_mat_init2[iter-1,], 0.1)
  newpost = lpost.LR(beta_star, X, y)
  oldpost = lpost.LR(beta_mat_init2[iter-1,], X, y)
  if (runif(1,0,1) > exp(newpost - oldpost)) {
    beta_mat_init2[iter,] = beta_mat_init2[iter-1,]
  } else {
    beta_mat_init2[iter,] = beta_star
    acc=acc + 1
  }
  #if (iter%%1000==0) {print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))

# Third initialisation
beta_mat_init3 <- matrix(NA,nrow=S,ncol=ncol(X))
k <- ncol(beta_mat_init3)
beta_mat_init3[1,] <- init[3,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k,beta_mat_init3[iter-1,], 0.1)
  newpost=lpost.LR(beta_star,X,y)
  oldpost=lpost.LR(beta_mat_init3[iter-1,],X,y)
  if(runif(1,0,1)>exp(newpost-oldpost)){
    beta_mat_init3[iter,]=beta_mat_init3[iter-1,]
  } else{
    beta_mat_init3[iter,]=beta_star
    acc=acc+1
  }
  #if(iter%%1000==0){print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))

# Forth initialisation
beta_mat_init4 <- matrix(NA,nrow=S,ncol=ncol(X))
k <- ncol(beta_mat_init4)
beta_mat_init4[1,] <- init[4,]
acc <- 0
for(iter in 2:S){
  beta_star <- rnorm(k,beta_mat_init4[iter-1,], 0.1)
  newpost=lpost.LR(beta_star,X,y)
  oldpost=lpost.LR(beta_mat_init4[iter-1,],X,y)
  if(runif(1,0,1)>exp(newpost-oldpost)){
    beta_mat_init4[iter,]=beta_mat_init4[iter-1,]
  } else{
    beta_mat_init4[iter,]=beta_star
    acc=acc+1
  }
  #if(iter%%1000==0){print(c(iter,acc/iter))}
}
print(c(iter, acc/iter))
```


Plot the chains for each coefficient (same plot)

```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat_init1[,1], type="l", col="magenta", main=expression(beta[0]))
lines(beta_mat_init2[,1], type="l", col="green")
lines(beta_mat_init3[,1], type="l", col="red")
lines(beta_mat_init4[,1], type="l", col="blue")
abline(h=fit$coefficients[1],col="red",lty=2)

plot(beta_mat_init1[,2], type="l", col="magenta", main=expression(beta[1]))  #, ylim=(c(-30, 50))
lines(beta_mat_init2[,2], type="l", col="green")
lines(beta_mat_init3[,2], type="l", col="red")
lines(beta_mat_init4[,2], type="l", col="blue")
abline(h=fit$coefficients[2],col="red",lty=2)

plot(beta_mat_init1[,3], type="l", col="magenta", main=expression(beta[2]))
lines(beta_mat_init2[,3], type="l", col="green")
lines(beta_mat_init3[,3], type="l", col="red")
lines(beta_mat_init4[,3], type="l", col="blue")
abline(h=fit$coefficients[3],col="red",lty=2)

plot(beta_mat_init1[,4], type="l", col="magenta", main=expression(beta[3]))
lines(beta_mat_init2[,4], type="l", col="green")
lines(beta_mat_init3[,4], type="l", col="red")
lines(beta_mat_init4[,4], type="l", col="blue")
abline(h=fit$coefficients[4],col="red",lty=2)

plot(beta_mat_init1[,5], type="l", col="magenta", main=expression(beta[4]))
lines(beta_mat_init2[,5], type="l", col="green")
lines(beta_mat_init3[,5], type="l", col="red")
lines(beta_mat_init4[,5], type="l", col="blue")
abline(h=fit$coefficients[5],col="red",lty=2)

plot(beta_mat_init1[,6], type="l", col="magenta", main=expression(beta[5]))
lines(beta_mat_init2[,6], type="l", col="green")
lines(beta_mat_init3[,6], type="l", col="red")
lines(beta_mat_init4[,6], type="l", col="blue")
abline(h=fit$coefficients[6],col="red",lty=2)
```

```{r, echo=FALSE}
par(mfrow=c(3,2))

plot(beta_mat_init1[,7], type="l", col="magenta", main=expression(beta[6]))  # , ylim=(c(-30, 30))
lines(beta_mat_init2[,7], type="l", col="green")
lines(beta_mat_init3[,7], type="l", col="red")
lines(beta_mat_init4[,7], type="l", col="blue")
abline(h=fit$coefficients[7],col="red",lty=2)

plot(beta_mat_init1[,8], type="l", col="magenta", main=expression(beta[7]))  # , ylim=(c(-30, 40))
lines(beta_mat_init2[,8], type="l", col="green")
lines(beta_mat_init3[,8], type="l", col="red")
lines(beta_mat_init4[,8], type="l", col="blue")
abline(h=fit$coefficients[8],col="red",lty=2)

plot(beta_mat_init1[,9], type="l", col="magenta", main=expression(beta[8]))
lines(beta_mat_init2[,9], type="l", col="green")
lines(beta_mat_init3[,9], type="l", col="red")
lines(beta_mat_init4[,9], type="l", col="blue")
abline(h=fit$coefficients[9],col="red",lty=2)

plot(beta_mat_init1[,10], type="l", col="magenta", main=expression(beta[9]))
lines(beta_mat_init2[,10], type="l", col="green")
lines(beta_mat_init3[,10], type="l", col="red")
lines(beta_mat_init4[,10], type="l", col="blue")
abline(h=fit$coefficients[10],col="red",lty=2)

plot(beta_mat_init1[,11], type="l", col="magenta", main=expression(beta[10]))
lines(beta_mat_init2[,11], type="l", col="green")
lines(beta_mat_init3[,11], type="l", col="red")
lines(beta_mat_init4[,11], type="l", col="blue")
abline(h=fit$coefficients[11],col="red",lty=2)

plot(beta_mat_init1[,12], type="l", col="magenta", main=expression(beta[11]))  # , ylim=(c(-30, 50))
lines(beta_mat_init2[,12], type="l", col="green")
lines(beta_mat_init3[,12], type="l", col="red")
lines(beta_mat_init4[,12], type="l", col="blue")
abline(h=fit$coefficients[12],col="red",lty=2)
```
```{r}
summ <- matrix(NA, nrow=12, ncol=2)
for (i in 1:12) {
  summ[i,1] = mean(beta_mat_init1[2000:10000,i])
  summ[i,2] = sd(beta_mat_init1[2000:10000,i])
}
colnames(summ) <- c("Mean_MH", "SD_MH")
rownames(summ) <- c("Intercept", "fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar",
                    "chlorides", "free_sulfur_dioxide", "total_sulfur_dioxide", "density",
                    "pH", "sulphates", "alcohol")
```

Histogram of spread of chain values
```{r}
# hist(beta_mat_init1[,1])
# ci0 <- quantile(beta_mat_init1[,1], prob=c(.025,.975)) 
coeffs <- c("Intercept", "Fixed Acidity", "Volatile Acidity", "Citric Acid", "Residual Sugar",
                    "Chlorides", "Free Sulfur Dioxide", "Total Sulfur Dioxide", "Density",
                    "pH", "Sulphates", "Alcohol")

```
```{r}
par(mfrow=c(3,2)) 
for (i in 1:6) {
hist(beta_mat_init1[,i], main=coeffs[i], prob=TRUE); abline(v=c(summ[i,1],quantile(beta_mat_init1[,i], prob=c(.025,.975))), col="red")
}
```
```{r}
par(mfrow=c(3,2)) 
for (i in 7:12) {
hist(beta_mat_init1[,i], main=coeffs[i], prob=TRUE); abline(v=c(summ[i,1],quantile(beta_mat_init1[,i], prob=c(.025,.975))), col="red")
}
```


```{r}
S <- 20000
beta_mat2 <- matrix(NA, nrow = S, ncol = ncol(X))
beta_mat2[1,] <- as.numeric(coefficients(fit))

y_new <- c(1)
x_new <- c(1, fixed_acidity, volatile_acidity, citric_acid, residual_sugar,
           chlorides, free_sulfur_dioxide, total_sulfur_dioxide, density,
           pH, sulphates, alcohol)
```
```{r}
library(mvtnorm)

# prediction

Omega_prop <- solve(t(X) %*% X)
k <- ncol(beta_mat2)
acc <- 0
for(iter in 2:S)
{
  # 1. Propose a new set of values
  beta_star <- rmvnorm(1, beta_mat2[iter-1,], 1.5 * Omega_prop)
  
  # 2. Compute the posterior density on the proposed value and on the old value  
  newpost=lpost.LR(t(beta_star), X, y)
  oldpost=lpost.LR(matrix(beta_mat2[iter-1,], ncol=1), X, y)
  
  # 3. Acceptance step
  if (runif(1, 0, 1) > exp(newpost - oldpost)) {
    beta_mat2[iter,] = beta_mat2[iter-1,]
  } else {
    beta_mat2[iter,] = beta_star
    acc = acc + 1
  }
  # 4. Print the stage of the chain
  if (iter%%1000 == 0){ print(c(iter, acc/iter)) }
  
  # 5. Prediction 
  p_new <- exp(sum(beta_mat2[iter,] * x_new) ) / (1 + exp(sum(beta_mat2[iter,] * x_new) ))
  y_new[iter] <- rbinom(1,1,prob=p_new)
}
```
```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat2[,1],type="l", ylab=expression(beta[0]))
abline(h=fit$coefficients[1],col="red",lty=2)
plot(beta_mat2[,2],type="l", ylab=expression(beta[1]))
abline(h=fit$coefficients[2],col="red",lty=2)
plot(beta_mat2[,3],type="l", ylab=expression(beta[2]))
abline(h=fit$coefficients[3],col="red",lty=2)
plot(beta_mat2[,4],type="l", ylab=expression(beta[3]))
abline(h=fit$coefficients[4],col="red",lty=2)
plot(beta_mat2[,5],type="l", ylab=expression(beta[4]))
abline(h=fit$coefficients[5],col="red",lty=2)
plot(beta_mat2[,6],type="l", ylab=expression(beta[5]))
abline(h=fit$coefficients[6],col="red",lty=2)
```
```{r, echo=FALSE}
par(mfrow=c(3,2))
plot(beta_mat2[,7],type="l", ylab=expression(beta[6]))
abline(h=fit$coefficients[7],col="red",lty=2)
plot(beta_mat2[,8],type="l", ylab=expression(beta[7]))
abline(h=fit$coefficients[8],col="red",lty=2)
plot(beta_mat2[,9],type="l", ylab=expression(beta[8]))
abline(h=fit$coefficients[9],col="red",lty=2)
plot(beta_mat2[,10],type="l", ylab=expression(beta[9]))
abline(h=fit$coefficients[10],col="red",lty=2)
plot(beta_mat2[,11],type="l", ylab=expression(beta[10]))
abline(h=fit$coefficients[11],col="red",lty=2)
plot(beta_mat2[,12],type="l", ylab=expression(beta[11]))
abline(h=fit$coefficients[12],col="red",lty=2)
```












